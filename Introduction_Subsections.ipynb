{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering Project\n",
    "\n",
    "#### Yelena Kernogitski and Mengshu Shao   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant aim of machine learning and pattern recognition is finding appropriate clusters that are able to accurately classify data points. Two standard approaches used in clustering are K-means and Expectation-Maximazation which allow for learning a mixture model. The latter has severe drawbacks where we must estimate the density of each cluster to be Gaussian due to parametric assumptions, and the log likelihood may result in getting caught in a local minima, and many various initial values may need to be used [1]. K-means clustering by itself leads to other problems, such as not being able to accomodate non-spherical data, and other complex datasets. A method that provides a possible solution in finding useful clusters in spectral clustering, which utilizes eigenvectors derived from the distance between points. An additional part of our algorithm uses the eigenvectors found in K-means clustering, as opposed to using the original dataset found. It has been found in empirical studies that the latter method is more accurate in classifying clusters [1]. In this report, we first implement a simple spectral clustering algorithm for clustering point in $\\mathbb{R}^n$. Second, we analyze how it works in an \"ideal\" case in which the points are exactly far apart. Then we apply the algorithm to a number of challenging clustering problems. We will attempt to optimize our algorithm by using various methods--such as vectorization, JIT, and cython wrapping funcions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm has been previously described in (Ng et al, 2002). Provided a set of points $S= {s_1,...,s_n}$ in $\\mathbb{R}^l$ that we want to clsuter into $k$ subsets:\n",
    "\n",
    "1. Define the affinity matrix $A$ $\\mathbb{R}^{nxn}$ by $A_{ij}=exp(-||s_i-s_j||^2 / 2\\sigma^2)$ if $i\\neq{j}$, and $A_{ii}=0$.\n",
    "    \n",
    "2. Create a diagonal matrix whose ($i$,$i$) element is the sum of $A's$ i-th row, and construct L, where $L= D^{-1/2}AD^{-1/2}$.\n",
    "    \n",
    "3. Find ${x_1,...,x_n}$, the $k$ largest eigenvectors of $L$, and create the matrix $X$, by placing the k eigenvectors in columns.\n",
    "    \n",
    "4. Use $X$ to form the matrix $Y$, by normalizing each X's rows to have unit length (i.e. $Y_{ij}=X_{ij}/(\\sum_{j}{}X_{ij}^2)^{1/2}$). \n",
    "    \n",
    "5. Treating each row of $Y$ as a point in $\\mathbb{R}^k$, cluster into $k$ clusters using K-means\n",
    "    \n",
    "6. Assign the original point $s_i$ to cluster $j$ if row $i$ of the matrix $Y$ was assigned to cluster $j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scaling parameter $\\sigma^2$ was found by minimizing the distortion of the Y matrix and the clustering centers that correspond to each assigned cluster. The distortion was found by summing over the Euclidean distances between each data point and the center of its assigned cluster. We found $\\sigma^2$ by using an iterative procedure to find which value of $\\sigma^2$ minimized the distortion. Generally, $\\sigma^2$ can be determined using human input, but this process automizes the procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Ng, Andrew Y., Michael I. Jordan, and Yair Weiss. \"On spectral clustering: Analysis and an algorithm.\" Advances in neural information processing systems 2 (2002): 849-856."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
